global:
  # zone: cluster.local (use only if your DNS server doesn't live in the same zone as kubecost)
  prometheus:
    enabled: true # If false, Prometheus will not be installed
    fqdn: http://cost-analyzer-prometheus-server.default.svc.cluster.local #example fqdn. Ignored if enabled: true

  thanos:
    enabled: false

  grafana:
    enabled: true # If false, Grafana will not be installed
    domainName: cost-analyzer-grafana.default.svc.cluster.local #example grafana domain Ignored if enabled: true
    scheme: "http" # http or https, for the domain name above.
    proxy: true # If true, the kubecost frontend will route to your grafana through its service endpoint

  notifications:
    slack: # Write to a webhook.
      enabled: false # Allow kubecost to write to your slackbot.
      webhook: https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX # Example Webhook
    alertmanager: # Supply an alertmanager FQDN to receive notifications from the app.
      enabled: false # If true, allow kubecost to write to your alertmanager
      fqdn: http://cost-analyzer-prometheus-server.default.svc.cluster.local #example fqdn. Ignored if prometheus.enabled: true

  podAnnotations: {}
    # iam.amazonaws.com/role: role-arn

kubecostChecks:
  enabled: true
  image: "ajaytripathy/kubecost-checks"
  resources:
    requests:
      cpu: "20m"
      memory: "100Mi"
    limits:
      cpu: "100m"
      memory: "200Mi"

kubecostFrontend:
  image: "ajaytripathy/kubecost-frontend"
  imagePullPolicy: Always
  resources:
    requests:
      cpu: "10m"
      memory: "55Mi"
    #limits:
    #  cpu: "100m"
    #  memory: "256Mi"

kubecost:
  image: "ajaytripathy/kubecost"
  resources:
    requests:
      cpu: "100m"
      memory: "55Mi"
    #limits:
    #  cpu: "100m"
    #  memory: "256Mi"

kubecostModel:
  image: "ajaytripathy/kubecost-cost-model"
  imagePullPolicy: Always
  resources:
    requests:
      cpu: "200m"
      memory: "55Mi"
    #limits:
    #  cpu: "800m"
    #  memory: "256Mi"

kubecostInit:
  image: "ajaytripathy/kubecost-init"
  imagePullPolicy: Always

ingress:
  enabled: false
  annotations:
    kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  paths: ["/"] # There's no need to route specifically to the pods-- we have an nginx deployed that handles routing
  hosts:
    - cost-analyzer.local
  tls: []
  #  - secretName: cost-analyzer-tls
  #    hosts:
  #      - cost-analyzer.local

nodeSelector: {}

# If true, enable creation of NetworkPolicy resources.
networkPolicy:
  enabled: false
#
# Define persistence volume for cost-analyzer
persistentVolume:
  size: 0.2Gi
  enabled: true # Note that setting this to false means configurations will be wiped out on pod restart.

service:
  type: ClusterIP

remoteWrite:
  postgres: 
    enabled: false
    initImage: "ajaytripathy/kubecost-sql-init"
    initImagePullPolicy: Always
    installLocal: true
    remotePostgresAddress: "" # ignored if installing locally
    persistentVolume:
      size: 200Gi
    auth:
      password: admin # change me

prometheus:
  extraScrapeConfigs: |
    - job_name: kubecost
      honor_labels: true
      scrape_interval: 1m
      scrape_timeout: 10s
      metrics_path: /metrics
      scheme: http
      dns_sd_configs:
      - names:
        - {{ template "cost-analyzer.serviceName" . }}
        type: 'A'
        port: 9003
    - job_name: kubecost-networking
      kubernetes_sd_configs:
        - role: pod
      relabel_configs:
      # Scrape only the the targets matching the following metadata
        - source_labels: [__meta_kubernetes_pod_label_app]
          action: keep
          regex:  {{ template "cost-analyzer.networkCostsName" . }}
  server:
    global:
      scrape_interval: 1m
      scrape_timeout: 10s
      evaluation_interval: 1m
      external_labels:
        cluster_id: cluster-one # Each cluster should have a unique ID
    persistentVolume:
      size: 32Gi
      enabled: true
  alertmanager:
    persistentVolume:
      enabled: true
  pushgateway:
    persistentVolume:
      enabled: true
  serverFiles:
    prometheus.yml:
        remote_write:
          - url: "http://pgprometheus-adapter:9201/write"
            write_relabel_configs:
              - source_labels: [__name__]
                regex: 'container_.*_allocation|container_.*_allocation_bytes|.*_hourly_cost|kube_pod_container_resource_requests_memory_bytes|container_memory_working_set_bytes|kube_pod_container_resource_requests_cpu_cores|kube_pod_container_resource_requests|pod_pvc_allocation|kube_namespace_labels|kube_pod_labels'
                action: keep
            queue_config:
              max_samples_per_send: 1000
        #remote_read:
        #  - url: "http://pgprometheus-adapter:9201/read"
    rules:
      groups:
        - name: CPU
          rules:
            - expr: sum(rate(container_cpu_usage_seconds_total{container_name!=""}[5m]))
              record: cluster:cpu_usage:rate5m
            - expr: rate(container_cpu_usage_seconds_total{container_name!=""}[5m])
              record: cluster:cpu_usage_nosum:rate5m
            - expr: avg(irate(container_cpu_usage_seconds_total{container_name!="POD", container_name!=""}[5m])) by (container_name,pod_name,namespace)
              record: kubecost_container_cpu_usage_irate
            - expr: sum(container_memory_working_set_bytes{container_name!="POD",container_name!=""}) by (container_name,pod_name,namespace)
              record: kubecost_container_memory_working_set_bytes
            - expr: sum(container_memory_working_set_bytes{container_name!="POD",container_name!=""})
              record: kubecost_cluster_memory_working_set_bytes

networkCosts:
  enabled: false
  image: gcr.io/kubecost1/kubecost-network-costs:v6
  imagePullPolicy: Always
  resources:
    #requests:
    #  cpu: "50m"
    #  memory: "20Mi"

serviceMonitor:
  enabled: false
  additionalLabels: {}

prometheusRule:
  enabled: false
  additionalLabels: {}

supportNFS: true

grafana:
  sidecar:
    dashboards:
      enabled: true
    datasources:
      enabled: true
      defaultDatasourceEnabled: true
